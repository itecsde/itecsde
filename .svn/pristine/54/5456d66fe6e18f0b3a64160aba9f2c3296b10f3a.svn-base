# encoding: utf-8

class Wikipediator
  include ActionView::Helpers::SanitizeHelper
  
  # wikify recibe prosa y devuelve un array de tags
  
  def wikify(prose)
    begin 
      #prose.force_encoding('binary')
      if prose != nil
        prose=prose.truncate(32000)
      end  
      url = "http://"+get_wikipediator_server+":8080/wikipediaminer/services/wikify?source=" + URI.encode(prose.gsub(/[^0-9a-z:,. ]/i, ''))
      page = Nokogiri::XML(open(url))
      tags = page.xpath("//message/detectedTopics/detectedTopic")
      return tags
    rescue Exception => e
      puts e.backtrace.inspect
      puts e.message 
      puts "Exception in wikify"    
    end
  end #wikify
  
  def wikify_it(prose)
    begin
      if prose != nil
        prose=prose.truncate(32000)
      end
      url = "http://"+get_wikipediator_server+":8080/wikipediaminer/services/wikify?source=" + URI.encode(prose.gsub(/[^0-9a-z:,. ]/i, ''))
      page = Nokogiri::XML(open(url))
      entries = page.xpath("//message/detectedTopics/detectedTopic")      
      tags = Array.new
      entries.each do |entry|
        tags << {:name => entry['title'], :weight => entry['weight'], :wikipedia_article_id => entry['id']}
      end 
      return tags
    rescue Exception => e
      puts e.backtrace.inspect
      puts e.message 
      puts "Exception in wikify"
      raise "Wikipediator exeception in method wikify_it " + e.message    
    end
  end
  
  def suggest(array_ids)
    begin
        list_ids=array_ids.map { |id| id }.join(",")
        url = "http://"+get_wikipediator_server+":8080/wikipediaminer/services/suggest?queryTopics=" + list_ids
        page = Nokogiri::XML(open(url))
        categories = page.xpath("//message/suggestionCategories/suggestionCategory")
        array_categories=Array.new
        categories.each do |category|
          array_categories << {:id => category['id'],:title => category['title'],:weight => category['weight']}
        end
      return array_categories
    rescue Exception => e
      puts e.backtrace.inspect
      puts e.message 
      puts "Exception in suggest"      
    end
  end #suggest
  
  
  #Deveulve los articulos sugeridos mas relevantes
  def suggest_articles(array_ids)
    begin
        list_ids=array_ids.map { |id| id }.join(",")
        url = "http://"+get_wikipediator_server+":8080/wikipediaminer/services/suggest?queryTopics=" + list_ids
        page = Nokogiri::XML(open(url))
        articles = page.xpath("//message/suggestionCategories/suggestionCategory/suggestion")
        
        array_articles=Array.new
        articles.each do |article|
          array_articles << {:id => article['id'],:title => article['title'],:weight => article['weight']} 
        end
        
        uncategorized_articles = page.xpath("//message/uncategorizedSuggestions/suggestion")
        uncategorized_articles.each do |article|
          array_articles << {:id => article['id'],:title => article['title'],:weight => article['weight']}
        end                
        
        return array_articles.sort_by { |hsh| hsh[:weight] }.reverse.uniq { |x| x[:title] }.first(10)
           
    rescue Exception => e
      puts e.backtrace.inspect
      puts e.message 
      puts "Exception in suggest"      
    end
  end #suggest  
  
  
  
  
  def search(name)
    begin   
        url = "http://"+get_wikipediator_server+":8080/wikipediaminer/services/search?query=" + URI.encode(name)
        page = Nokogiri::XML(open(url))
        entries = page.xpath("//label/senses/sense")
      return entries
    rescue Exception => e
      puts e.backtrace.inspect
      puts e.message 
      puts "Exception in search"      
    end
  end #search
  
  def complex_search(text)
    begin   
        url = "http://"+get_wikipediator_server+":8080/wikipediaminer/services/search?complex=true&query=" + URI.encode(text)
        page = Nokogiri::XML(open(url))
        entries = page.xpath("//label/senses/sense[1]")
      return entries
    rescue Exception => e
      puts e.backtrace.inspect
      puts e.message 
      puts "Exception in complex_search"      
    end
  end #complex_search
  
  def complex_search_it(text)
    begin   
        url = "http://"+get_wikipediator_server+":8080/wikipediaminer/services/search?complex=true&query=" + URI.encode(text)
        page = Nokogiri::XML(open(url))
        labels = page.xpath("//label")
        filtered_labels = Array.new
        labels.each do |label|
          if label['linkProbability'].to_f > 0.01
            filtered_labels << label
          end
        end
        entries = Array.new
        filtered_labels.each do |filtered_label|
          entries << filtered_label.xpath(".//senses/sense[1]").first
        end
        tags = Array.new
        entries.each do |entry|
          tags << {:name => entry['title'], :weight => entry['weight'], :wikipedia_article_id => entry['id']}
        end
      return tags
    rescue Exception => e
      puts e.backtrace.inspect
      puts e.message 
      puts "Exception in complex_search"
      raise "Exception in complex_search_it"
    end
  end #complex_search
   
   
  def getDefinition(title)    
    begin   
        url = "http://"+get_wikipediator_server+":8080/wikipediaminer/services/exploreArticle?definition=true&definitionLength=long&title=" + URI.encode(title)
        page = Nokogiri::XML(open(url))
        definition = page.xpath("//definition")
        definition=strip_tags(definition.text)
      return definition
    rescue Exception => e
      puts e.backtrace.inspect
      puts e.message 
      puts "Exception in getDefinition"      
    end 
  end #getDefinition
  
  
  def translations(id)
    begin   
        url = "http://"+get_wikipediator_server+":8080/wikipediaminer/services/exploreArticle?id=" + id.to_s + "&translations=true"
        page = Nokogiri::XML(open(url))
        languages = page.xpath("//message/translations/tranlation")
      return languages
    rescue Exception => e
      puts e.backtrace.inspect
      puts e.message 
      puts "Exception in translations"      
    end
  end #translations
  
  def parentCategories(id)
    begin   
        url = "http://"+get_wikipediator_server+":8080/wikipediaminer/services/exploreArticle?id=" + id.to_s + "&parentCategories"
        page = Nokogiri::XML(open(url))
        parentCategories = page.xpath("//message/parentCategories/parentCategory")
      return parentCategories
    rescue Exception => e
      puts e.backtrace.inspect
      puts e.message 
      puts "Exception in parentCategories"      
    end
  end #parentCategories
  
  ####################################################################################
  ##### DEVUELVE UN ARRAY CON LAS URLS EN TODOS LOS IDIOMAS DE LA UE DISPONIBLES
  ##### DE UN PROGRAMA SOFTWARE DE LA WIKIPEDIA
  #######################################################
  
  def application_translation_urls(name)
    begin
      array_ids = []
      array_matches = []
      url_idiomas = []
      idiomas_ue = ["gl","de","bg","cs","hr","da","sk","sl","es","et","fi","fr","el","hu","en","ga","it","lv","lt","mt","nl","pl","pt","ro","sv","tr","no"]
      id=-1
      i=0
      matches = 0
      wikipediator = Wikipediator.new
      entries = wikipediator.search(name)      
      if entries.length!=0  
        if entries.length > 1
          entries.each do |entry|
            parent_categories = wikipediator.parentCategories(entry['id'])
            parent_categories.each do |parent_category|
              if ApplicationParentCategory.find_by_name(parent_category['title'])
                matches+=1
              end
            end
            if matches > 0
              array_ids << entry['id']
              array_matches << matches
              matches = 0
            end 
          end
          #obtenemos el mayor numero de matches
          maximo = array_matches.max
          if maximo != nil
            max_index = array_matches.index(maximo)
            #id es el identificador del elemento con mayor numero de matches
            id = array_ids[max_index]
          end     
        else
          parent_categories = wikipediator.parentCategories(entries[0]['id'])
          parent_categories.each do |parent_category|
            if ApplicationParentCategory.find_by_name(parent_category['title'])
              matches+=1
            end
          end
          if matches>0
            id = entries[0]['id']
          end
        end
        puts "Procedemos a obtener las url translations del id: " + id.to_s
        translations = wikipediator.translations(id)
        translations.each do |translation|
          if translation['lang'].in? idiomas_ue
            url_idioma = "http://" + translation['lang'] + ".wikipedia.org/wiki/" + translation.text
            url_idiomas << {:url => url_idioma, :lang => translation['lang']}
          end
        end      
      end
      return url_idiomas
    rescue Exception => e
      puts "Failed url_translations"
      puts e.message
      puts e.backtrace.inspect
    end
  end #application_translations_url
  
  ###############################################################################
  #### DEVUELVE UN ARRAY CON LAS URLS EN TODOS LOS IDIOMAS DE LA UE DISPONIBLES
  #### DEL NOMBRE name
  ##############################################################################
  
  def translations_urls(name)
    array_ids = []
    array_matches = []
    url_idiomas = []
    idiomas_ue = ["gl","de","bg","cs","hr","da","sk","sl","es","et","fi","fr","el","hu","en","ga","it","lv","lt","mt","nl","pl","pt","ro","sv","tr","no"]
    wikipediator = Wikipediator.new
    entries = wikipediator.search(name)
    if entries.length > 0   
      translations = wikipediator.translations(entries[0]['id'])
      translations.each do |translation|
        if translation['lang'].in? idiomas_ue
          url_idioma = "http://" + translation['lang'] + ".wikipedia.org/wiki/" + translation.text
          url_idiomas << {:url => url_idioma, :lang => translation['lang'], :name => translation.text}
        end
      end      
    end
    return url_idiomas
    #puts url_idiomas
  end
  
  
 
  def get_wikipediator_server
    if ENV['RAILS_ENV'] == "development" 
      wiki_servers = ["192.168.1.82"]
    else
      wiki_servers = ["10.0.0.2","10.0.0.3","10.0.0.4"] 
    end       
    
    actual_wiki_server=WikipediatorServerCounter.first
    if actual_wiki_server == nil
       new_wiki_server = WikipediatorServerCounter.new
       new_wiki_server.counter = 0
       new_wiki_server.server_ip = wiki_servers[0]
       new_wiki_server.save
       puts "Wikipediador :" + new_wiki_server.server_ip
       return new_wiki_server.server_ip
    else 
      if (actual_wiki_server.counter + 1) >= wiki_servers.size
        actual_wiki_server.counter = 0
        actual_wiki_server.server_ip = wiki_servers[0]
      else
        actual_wiki_server.counter =  actual_wiki_server.counter + 1
        actual_wiki_server.server_ip =  wiki_servers[actual_wiki_server.counter]          
      end
      actual_wiki_server.save
      puts "Wikipediador :" + actual_wiki_server.server_ip
      return actual_wiki_server.server_ip
    end
        
  end
  
  
end
