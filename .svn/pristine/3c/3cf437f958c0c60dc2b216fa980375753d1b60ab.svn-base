# encoding: utf-8
require 'net/http'
require 'net/https'
require 'uri'

#require "capybara/dsl"
class Classify
   include ActionView::Helpers::SanitizeHelper
   def classify_it(wikitopics, sections, wikipediator_ip = nil)
      begin
                  
         scraper = Scraper.new
         wikipediator = Wikipediator.new
                          
         newspaper_sections = sections
         
         categories = Array.new
         total_relatedness = 0
              
         newspaper_sections.each do |section|
            category = wikipediator.complex_search_it(section, wikipediator_ip)
            categories << {:name => category[0][:name], :wikipedia_article_id => category[0][:wikipedia_article_id]}
         end
                  
         #wikitopics = wikipediator.wikify_it(text)
         
         categories.each do |category|
            wikitopics.each do |wikitopic|
               relatedness = wikipediator.compare(wikitopic[:wikipedia_article_id],category[:wikipedia_article_id], wikipediator_ip)
               total_relatedness = total_relatedness + relatedness.to_f
            end
            relatedness_mean = total_relatedness / wikitopics.size
            category = category[:relatedness_mean] = relatedness_mean 
            relatedness_mean = 0
            total_relatedness = 0
         end 
             
         categories = categories.sort_by { |hsh| hsh[:relatedness_mean] }
         
         puts "WIKITOPICS"
         puts wikitopics
         
         puts "CATEGORIES"
         puts categories
         
         puts "CATEGORY SELECTED: "
         puts categories.last     
                  
         return categories.last    
      rescue Exception => e
         puts "Exception classify_it"
         puts e.message
         puts e.backtrace.inspect
      end
   end
   
   def classify_it_with_weight(wikitopics, sections, wikipediator_ip = nil)
      begin
                  
         scraper = Scraper.new
         wikipediator = Wikipediator.new
                          
         categories = Array.new
         total_relatedness = 0
              
         newspaper_sections = sections              
              
         newspaper_sections.each do |section|
            category = wikipediator.complex_search_it(section,wikipediator_ip)
            categories << {:name => category[0][:name], :wikipedia_article_id => category[0][:wikipedia_article_id]}
         end
                  
         #wikitopics = wikipediator.wikify_it(text)
         
         categories.each do |category|
            wikitopics.each do |wikitopic|
               relatedness = (wikipediator.compare(wikitopic[:wikipedia_article_id],category[:wikipedia_article_id],wikipediator_ip).to_f * wikitopic[:weight].to_f)
               total_relatedness = total_relatedness + relatedness.to_f
            end
            relatedness_mean = total_relatedness / wikitopics.size
            category = category[:relatedness_mean] = relatedness_mean 
            relatedness_mean = 0
            total_relatedness = 0
         end 
             
         categories = categories.sort_by { |hsh| hsh[:relatedness_mean] }
         
         puts "WIKITOPICS"
         puts wikitopics
         
         puts "CATEGORIES"
         puts categories
         
         puts "CATEGORY SELECTED: "
         puts categories.last     
                  
         return categories.last    
      rescue Exception => e
         puts "Exception classify_it_with_weight"
         puts e.message
         puts e.backtrace.inspect
      end
   end
   
   
   def self.generate_countries_and_cities
      begin
         puts "Generating countries and cities array...."
         Cities.data_path = 'cities'
         countries = Array.new      
         countries_code = Array.new 
         cities = Array.new
         countries_and_cities = Array.new
         Carmen::Country.all.each do |carmen_country|
            countries << carmen_country.name.downcase
            countries_code << carmen_country.code
         end
         countries_code.each do |country_code|
            Cities.cities_in_country(country_code).each do |city|
               cities << city.first.downcase
            end
         end   
         countries_and_cities = countries + cities
         puts "Done!"
         return countries_and_cities
      rescue Exception => e
         puts "Exception generate_countries_and_cities"
         puts e.message
         puts e.backtrace.inspect
      end
   end
   
   def self.generate_countries
      begin
         countries = Array.new 
         Carmen::Country.all.each do |carmen_country|
            countries << carmen_country.name.downcase
         end
         return countries
      rescue Exception => e
         puts "Exception generate_countries"
         puts e.message
         puts e.backtrace.inspect
      end
   end
   
     
   def classify_it_without_countries(wikitopics,sections, wikipediator_ip = nil)
      begin
      
         scraper = Scraper.new
         wikipediator = Wikipediator.new

         newspaper_sections = sections
                
         categories = Array.new
         total_relatedness = 0
                            
         newspaper_sections.each do |section|
            category = wikipediator.complex_search_it(section,wikipediator_ip)
            categories << {:name => category[0][:name], :wikipedia_article_id => category[0][:wikipedia_article_id]}
         end
                         
         categories.each do |category|
            wikitopics.each do |wikitopic|
               if !$countries.include? wikitopic[:name].downcase
                  relatedness = (wikipediator.compare(wikitopic[:wikipedia_article_id],category[:wikipedia_article_id],wikipediator_ip).to_f * wikitopic[:weight].to_f)
                  total_relatedness = total_relatedness + relatedness.to_f
               end
            end
            relatedness_mean = total_relatedness / wikitopics.size
            category = category[:relatedness_mean] = relatedness_mean 
            relatedness_mean = 0
            total_relatedness = 0
         end 
             
         categories = categories.sort_by { |hsh| hsh[:relatedness_mean] }
         
         puts "WIKITOPICS"
         puts wikitopics
         
         puts "CATEGORIES"
         puts categories
         
         puts "CATEGORY SELECTED: "
         puts categories.last     
                  
         return categories.last    
      rescue Exception => e
         puts "Exception classify_it_without_countries"
         puts e.message
         puts e.backtrace.inspect
      end
   end   
   
   def classify_it_with_broader_sections(wikitopics, sections)
      begin
                  
         scraper = Scraper.new
         wikipediator = Wikipediator.new
                          
         newspaper_sections = sections
         
         categories = Array.new
         total_relatedness = 0
              
         newspaper_sections.each do |section|
            category = wikipediator.complex_search_it(section)
            categories << {:name => category[0][:name], :wikipedia_article_id => category[0][:wikipedia_article_id]}
         end
                         
         categories.each do |category|
            wikitopics.each do |wikitopic|
               relatedness = wikipediator.compare(wikitopic[:wikipedia_article_id],category[:wikipedia_article_id])
               total_relatedness = total_relatedness + relatedness.to_f
            end
            relatedness_mean = total_relatedness / wikitopics.size
            category = category[:relatedness_mean] = relatedness_mean 
            relatedness_mean = 0
            total_relatedness = 0
         end 
             
         categories = categories.sort_by { |hsh| hsh[:relatedness_mean] }
         
         puts "WIKITOPICS"
         puts wikitopics
         
         puts "CATEGORIES"
         puts categories
         
         puts "CATEGORY SELECTED: "
         puts categories.last     
                  
         return categories.last    
      rescue Exception => e
         puts "Exception classify_it_with_broader_sections"
         puts e.message
         puts e.backtrace.inspect
      end
   end   
   
      
   
     
   def classify_stored_reports(method, sections, remove_outliers, threshold)
      begin
         method = method.downcase
         wikipediator = Wikipediator.new   
         report_feeds = Array.new
                  
         Report.where(:section => nil).each do |report|
            begin      
               wikitopics = Array.new
               if remove_outliers == true
                  annotations = remove_outliers(report,threshold)
               else
                  annotations = report.taggable_tag_annotations
               end
               annotations.each do |wikitopic|
                  wikitopics << {:name =>wikitopic.tag.name, :weight => wikitopic.weight, :wikipedia_article_id => wikitopic.wikipedia_article_id}
               end
               puts report.id
               begin
                  if method == "basic"
                     section = classify_it(wikitopics, sections)
                  elsif method == "with_weight"
                     section = classify_it_with_weight(wikitopics, sections)
                  elsif method == "without_countries"
                     section = classify_it_without_countries(wikitopics, sections)
                  end            
                  report.section = section[:name]
                  report.save
               rescue
                  section = nil
               end
            rescue
               section = nil
            end            
         end
      rescue Exception => e
         puts "Exception classify_stored_reports"
         puts e.message
         puts e.backtrace.inspect
      end              
   end  
     
   def classify_report(report, method, sections, remove_outliers, threshold, wikipediator_ip = nil)
      begin
         method = method.downcase
         wikipediator = Wikipediator.new   
         report_feeds = Array.new
                    
         wikitopics = Array.new
         if remove_outliers == true
            annotations = remove_outliers(report,threshold)
         else
            annotations = report.taggable_tag_annotations
         end
         annotations.each do |wikitopic|
            wikitopics << {:name =>wikitopic.tag.name, :weight => wikitopic.weight, :wikipedia_article_id => wikitopic.wikipedia_article_id}
         end
         puts report.id
         begin
            if method == "basic"
               section = classify_it(wikitopics, sections, wikipediator_ip)
            elsif method == "with_weight"
               section = classify_it_with_weight(wikitopics, sections, wikipediator_ip)
            elsif method == "without_countries"
               section = classify_it_without_countries(wikitopics, sections, wikipediator_ip)
            end            
            report.section = section[:name]
            report.save
         rescue Exception => e
            puts "Exception saving section"
            puts e.message
            puts e.backtrace.inspect
            section = nil
         end            
      rescue Exception => e
         puts "Exception classify_stored_report"
         puts e.message
         puts e.backtrace.inspect
      end              
   end   
   
   #receives a report an a threshold and returns an annotations filtered array
   def remove_outliers(report,threshold)
      begin
         wikipediator = Wikipediator.new
         filtered_annotations = Array.new
         totals = Array.new             

         if threshold.class == "String"
            threshold = threshold.downcase
         end

         terms = report.taggable_tag_annotations.map{|annotation| annotation.tag.name}
              
         annotations = report.taggable_tag_annotations.map{|annotation| annotation}
         
         annotations.each do |annotation|
            puts annotation.wikipedia_article_id
         end                 
            
         annotations.each do |annotation_x|
            total_relatedness = 0
            annotations.each do |annotation_y|            
               relatedness = wikipediator.compare(annotation_x.wikipedia_article_id.to_i, annotation_y.wikipedia_article_id.to_i)
               total_relatedness = total_relatedness + relatedness.to_f
            end
            puts "Annotations Size: " + annotations.size.to_s
            total_relatedness = total_relatedness / annotations.size.to_f
            if threshold != "gravitational center"
               if total_relatedness >= threshold
                  filtered_annotations << annotation_x
                  totals << {:annotation => annotation_x, :name => annotation_x.tag.name, :relatedness => total_relatedness}
               end
            elsif threshold == "gravitational center"
               filtered_annotations << annotation_x
               totals << {:annotation => annotation_x, :name => annotation_x.tag.name, :relatedness => total_relatedness}   
            end
         end
         totals = totals.sort_by { |hsh| hsh[:relatedness] }
         totals.each do |total|
            puts total[:name].to_s + " " + total[:relatedness].to_s
         end
         if threshold == "gravitational center"
            filtered_annotations = Array.new
            filtered_annotations << totals.last[:annotation]
            return filtered_annotations
         end
         return filtered_annotations
      rescue Exception => e
         puts "Exception remove outliers"
         puts e.message
         puts e.backtrace.inspect
      end
   end
   
   def reuters_statistics(method)
      begin      
      wikipediator = Wikipediator.new   
      
      sections = [{:url_section => "http://www.reuters.com/news/archive/healthNews?view=page&pageSize=10&page=", :section => wikipediator.complex_search_it("Health")[0][:name]},
         {:url_section => "http://www.reuters.com/news/archive/artsNews?view=page&pageSize=10&page=", :section => wikipediator.complex_search_it("Art")[0][:name]},
         {:url_section => "http://www.reuters.com/news/archive/politicsNews?view=page&pageSize=10&page=", :section => wikipediator.complex_search_it("Politics")[0][:name]},
         {:url_section => "http://www.reuters.com/news/archive/sportsNews?view=page&pageSize=10&page=", :section => wikipediator.complex_search_it("Sport")[0][:name]},
         {:url_section => "http://www.reuters.com/news/archive/scienceNews?view=page&pageSize=10&page=", :section => wikipediator.complex_search_it("Science")[0][:name]},
         {:url_section => "http://www.reuters.com/news/archive/technologyNews?view=page&pageSize=10&page=", :section => wikipediator.complex_search_it("Technology")[0][:name]},
         {:url_section => "http://www.reuters.com/news/archive/GCA-Economy2010?view=page&pageSize=10&page=", :section => wikipediator.complex_search_it("Economy")[0][:name]},
         {:url_section => "http://www.reuters.com/news/archive/businessNews?view=page&pageSize=10&page=" , :section => wikipediator.complex_search_it("Business")[0][:name]},
         {:url_section => "http://www.reuters.com/news/archive/Fashion?view=page&pageSize=10&page=" , :section => wikipediator.complex_search_it("Fashion")[0][:name]}]
      
      report_sections = Array.new
      
      Report.all.each do |report|
         if !report_sections.include? report.scraped_from
            report_sections << report.scraped_from
         end 
      end
           
      report_sections.each do |report_section|          
         selected_section = sections.find {|x| x[:url_section] == report_section }       
         puts selected_section        
         section = selected_section[:section]        
         puts section            
         well_classified = Report.where(:scraped_from => report_section, :section => section).size
         health_classified = Report.where(:scraped_from => report_section, :section => "Health").size
         art_classified = Report.where(:scraped_from => report_section, :section => "Art").size
         politics_classified = Report.where(:scraped_from => report_section, :section => "Politics").size
         sport_classified = Report.where(:scraped_from => report_section, :section => "Sport").size
         science_classified = Report.where(:scraped_from => report_section, :section => "Science").size
         technology_classified = Report.where(:scraped_from => report_section, :section => "Technology").size
         economy_classified = Report.where(:scraped_from => report_section, :section => "Economy").size
         business_classified = Report.where(:scraped_from => report_section, :section => "Business").size
         fashion_classified = Report.where(:scraped_from => report_section, :section => "Fashion").size        
         not_classified = Report.where(:scraped_from => report_section, :section => nil).size
         bad_classified = Report.where(:scraped_from => report_section).size - not_classified - well_classified      
         well_classified_percentage = well_classified.to_f / (well_classified.to_f + bad_classified.to_f)        
         puts well_classified_percentage
         date = Time.now
         filename = "reuters_" + date.to_s + "_statistics_" + method + ".txt"                
         File.open(filename, 'a') do |f2|
            f2.puts
            f2.puts "Section: "  + section.to_s
            f2.puts "---------------------------------------------"
            f2.puts "Health classified: " + health_classified.to_s 
            f2.puts "Art classified: " + art_classified.to_s 
            f2.puts "Politics classified: " + politics_classified.to_s 
            f2.puts "Sport classified: " + sport_classified.to_s 
            f2.puts "Science classified: " + science_classified.to_s 
            f2.puts "Technology classified: " + technology_classified.to_s 
            f2.puts "Economy classified: " + economy_classified.to_s 
            f2.puts "Business classified: " + business_classified.to_s     
            f2.puts "Fashion classified: " + fashion_classified.to_s                                       
            f2.puts
            f2.puts "Total: " + Report.where(:scraped_from => report_section).size.to_s 
            f2.puts "Classified: " + (Report.where(:scraped_from => report_section).size - not_classified).to_s
            f2.puts "Not classified: " + not_classified.to_s               
            f2.puts "Well classified: " + well_classified.to_s        
            f2.puts "Bad classified: " + bad_classified.to_s
            f2.puts "Well classified Percentage: " + well_classified_percentage.to_s
            f2.puts    
         end
      end
      rescue Exception => e
         puts "Exception reuters statistics"
         puts e.message
         puts e.backtrace.inspect
      end
   end 
    
    
   def rss_reuters_statistics(date,method)
      begin      
      wikipediator = Wikipediator.new   
      
      rss_feeds = [{:url_feed => "http://feeds.reuters.com/reuters/healthNews", :section => wikipediator.complex_search_it("Health")[0][:name]},
         {:url_feed => "http://feeds.reuters.com/news/artsculture", :section => wikipediator.complex_search_it("Art")[0][:name]},
         {:url_feed => "http://feeds.reuters.com/Reuters/PoliticsNews", :section => wikipediator.complex_search_it("Politics")[0][:name]},
         {:url_feed => "http://feeds.reuters.com/reuters/sportsNews", :section => wikipediator.complex_search_it("Sport")[0][:name]},
         {:url_feed => "http://feeds.reuters.com/reuters/scienceNews", :section => wikipediator.complex_search_it("Science")[0][:name]},
         {:url_feed => "http://feeds.reuters.com/reuters/technologyNews", :section => wikipediator.complex_search_it("Technology")[0][:name]},
         {:url_feed => "http://feeds.reuters.com/news/economy", :section => wikipediator.complex_search_it("Economy")[0][:name]},
         {:url_feed => "http://feeds.reuters.com/reuters/businessNews" , :section => wikipediator.complex_search_it("Business")[0][:name]}]
      
      report_feeds = Array.new
      
      Report.all.each do |report|
         if !report_feeds.include? report.scraped_from
            report_feeds << report.scraped_from
         end 
      end
           
      report_feeds.each do |report_feed|          
         selected_rss_feed = rss_feeds.find {|x| x[:url_feed] == report_feed }       
         puts selected_rss_feed        
         section = selected_rss_feed[:section]        
         puts section            
         well_classified = Report.where(:scraped_from => report_feed, :section => section).size
         health_classified = Report.where(:scraped_from => report_feed, :section => "Health").size
         art_classified = Report.where(:scraped_from => report_feed, :section => "Art").size
         politics_classified = Report.where(:scraped_from => report_feed, :section => "Politics").size
         sport_classified = Report.where(:scraped_from => report_feed, :section => "Sport").size
         science_classified = Report.where(:scraped_from => report_feed, :section => "Science").size
         technology_classified = Report.where(:scraped_from => report_feed, :section => "Technology").size
         economy_classified = Report.where(:scraped_from => report_feed, :section => "Economy").size
         business_classified = Report.where(:scraped_from => report_feed, :section => "Business").size
         education_classified = Report.where(:scraped_from => report_feed, :section => "Education").size
         fashion_classified = Report.where(:scraped_from => report_feed, :section => "Fashion").size
         culture_classified = Report.where(:scraped_from => report_feed, :section => "Culture").size         
         not_classified = Report.where(:scraped_from => report_feed, :section => nil).size
         bad_classified = Report.where(:scraped_from => report_feed).size - not_classified - well_classified      
         well_classified_percentage = well_classified.to_f / (well_classified.to_f + bad_classified.to_f)        
         puts well_classified_percentage
         if method == "basic"
            filename = "reuters_" + date + "_statistics_basic_method.txt"
         elsif method == "with_weight"
            filename = "reuters_" + date + "_statistics_with_weight_method.txt"
         elsif method == "without_countries"
            filename = "reuters_" + date + "_statistics_without_countries_method.txt"
         end                 
         File.open(filename, 'a') do |f2|
            f2.puts
            f2.puts "Section: "  + section.to_s
            f2.puts "---------------------------------------------"
            f2.puts "Health classified: " + health_classified.to_s 
            f2.puts "Art classified: " + art_classified.to_s 
            f2.puts "Politics classified: " + politics_classified.to_s 
            f2.puts "Sport classified: " + sport_classified.to_s 
            f2.puts "Science classified: " + science_classified.to_s 
            f2.puts "Technology classified: " + technology_classified.to_s 
            f2.puts "Economy classified: " + economy_classified.to_s 
            f2.puts "Business classified: " + business_classified.to_s     
            f2.puts "Education classified: " + education_classified.to_s
            f2.puts "Fashion classified: " + fashion_classified.to_s  
            f2.puts "Culture classified: " + culture_classified.to_s                                        
            f2.puts
            f2.puts "Total: " + Report.where(:scraped_from => report_feed).size.to_s 
            f2.puts "Classified: " + (Report.where(:scraped_from => report_feed).size - not_classified).to_s
            f2.puts "Not classified: " + not_classified.to_s               
            f2.puts "Well classified: " + well_classified.to_s        
            f2.puts "Bad classified: " + bad_classified.to_s
            f2.puts "Well classified Percentage: " + well_classified_percentage.to_s
            f2.puts    
         end
      end
      rescue Exception => e
         puts "Exception reuters statistics"
         puts e.message
         puts e.backtrace.inspect
      end
   end 
         
   def rss_dailymail_statistics(date,method)
      begin      
      wikipediator = Wikipediator.new   
      
      rss_feeds = [{:url_feed => "http://www.dailymail.co.uk/sport/index.rss", :section => wikipediator.complex_search_it("Sport")[0][:name]},
         {:url_feed => "http://www.dailymail.co.uk/health/index.rss", :section => wikipediator.complex_search_it("Health")[0][:name]},
         {:url_feed => "http://www.dailymail.co.uk/sciencetech/index.rss", :section => wikipediator.complex_search_it("Science")[0][:name]},
         {:url_feed => "http://www.dailymail.co.uk/money/index.rss", :section => wikipediator.complex_search_it("Economy")[0][:name]},
         {:url_feed => "http://www.dailymail.co.uk/femail/fashionfinder/index.rss", :section => wikipediator.complex_search_it("Fashion")[0][:name]},
         {:url_feed => "http://www.dailymail.co.uk/tvshowbiz/index.rss", :section => wikipediator.complex_search_it("ShowBusiness")[0][:name]}]
      
      report_feeds = Array.new
      
      Report.all.each do |report|
         if !report_feeds.include? report.scraped_from
            report_feeds << report.scraped_from
         end 
      end
           
      report_feeds.each do |report_feed|          
         selected_rss_feed = rss_feeds.find {|x| x[:url_feed] == report_feed }       
         puts selected_rss_feed        
         section = selected_rss_feed[:section]        
         puts section            
         well_classified = Report.where(:scraped_from => report_feed, :section => section).size
         health_classified = Report.where(:scraped_from => report_feed, :section => "Health").size
         sport_classified = Report.where(:scraped_from => report_feed, :section => "Sport").size
         science_classified = Report.where(:scraped_from => report_feed, :section => "Science").size
         economy_classified = Report.where(:scraped_from => report_feed, :section => "Economy").size
         fashion_classified = Report.where(:scraped_from => report_feed, :section => "Fashion").size   
         show_business_classified = Report.where(:scraped_from => report_feed, :section => "ShowBusiness").size               
         not_classified = Report.where(:scraped_from => report_feed, :section => nil).size
         bad_classified = Report.where(:scraped_from => report_feed).size - not_classified - well_classified      
         well_classified_percentage = well_classified.to_f / (well_classified.to_f + bad_classified.to_f)        
         puts well_classified_percentage
         if method == "basic"
            filename = "dailymail_" + date + "_statistics_basic_method.txt"
         elsif method == "with_weight"
            filename = "dailymail_" + date + "_statistics_with_weight_method.txt"
         elsif method == "without_countries"
            filename = "dailymail_" + date + "_statistics_without_countries_method.txt"
         end                 
         File.open(filename, 'a') do |f2|
            f2.puts
            f2.puts "Section: "  + section.to_s
            f2.puts "---------------------------------------------"
            f2.puts "Health classified: " + health_classified.to_s 
            f2.puts "Sport classified: " + sport_classified.to_s 
            f2.puts "Science classified: " + science_classified.to_s 
            f2.puts "Economy classified: " + economy_classified.to_s 
            f2.puts "Fashion classified: " + fashion_classified.to_s                                       
            f2.puts "Show Business classified: " + show_business_classified.to_s             
            f2.puts
            f2.puts "Total: " + Report.where(:scraped_from => report_feed).size.to_s 
            f2.puts "Classified: " + (Report.where(:scraped_from => report_feed).size - not_classified).to_s
            f2.puts "Not classified: " + not_classified.to_s               
            f2.puts "Well classified: " + well_classified.to_s        
            f2.puts "Bad classified: " + bad_classified.to_s
            f2.puts "Well classified Percentage: " + well_classified_percentage.to_s
            f2.puts    
         end
      end
      rescue Exception => e
         puts "Exception dailymail statistics"
         puts e.message
         puts e.backtrace.inspect
      end
   end    
   
     
   def reuters_categories_dispersion
      begin
         wikipediator = Wikipediator.new
         wikisections = Array.new
         relatedness = 0.0
         newspaper_sections = ["Business", "Technology", "Science", "Health", "Sport", "Art", "Fashion", "Politics", "Education", "Culture", "Economy"]
         newspaper_sections.each do |section|
            wikisections << wikipediator.complex_search_it(section)  
         end 
         
         File.open('categories_dispersion.txt', 'w') do |f2| 
            f2.puts "            | Business |Technology| Science  |  Health  |  Sport   |   Art    | Fashion  | Politics |Education | Culture  | Economy |"                                    
            wikisections.each_with_index do |wikisection_x, index_x|
               f2.puts "--------------------------------------------------------------------------------------------------------------------------------------"
               f2.print wikisection_x[0][:name]
               case wikisection_x[0][:name]
               when "Business"
               f2.print "    |   "
               when "Technology"
               f2.print "  |   "   
               when "Science"
               f2.print "     |   "   
               when "Health"
               f2.print "      |   "   
               when "Sport"
               f2.print "       |   "   
               when "Art"
               f2.print "         |   "   
               when "Fashion"
               f2.print "     |   "  
               when "Politics"
               f2.print "    |   "   
               when "Education"
               f2.print "   |   "   
               when "Culture"
               f2.print "     |   "   
               when "Economy"
               f2.print "     |   "   
               end                      
               wikisections.each_with_index do |wikisection_y, index_y|
                  relatedness = wikipediator.compare(wikisection_x[0][:wikipedia_article_id],wikisection_y[0][:wikipedia_article_id])
                  f2.print "%.2f" % relatedness + "   |   "
               end
               f2.puts 
            end
            f2.puts "--------------------------------------------------------------------------------------------------------------------------------------"       
         end #file
      rescue Exception => e
         puts "Exception reuters_categories_dispersion"
         puts e.message
         puts e.backtrace.inspect
      end
   end
   
   def classify_it_naive_bayes
      begin
         $stdout = File.new('console_naive_bayes.out', 'w')
         $stdout.sync = true
         
         date = Time.now
         
         sections = ["Business", "Technology", "Science", "Health", "Sport", "Art", "Fashion", "Politics", "Economy"]
         naive_bayes = NaiveBayes.new(sections)
                  
         puts "Training Health..."
         Report.where(:scraped_from => "http://www.reuters.com/news/archive/healthNews?view=page&pageSize=10&page=").first(400).each do |report|
            naive_bayes.train("Health",report.info_to_wikify)
         end
         puts "Training Art..."
         Report.where(:scraped_from => "http://www.reuters.com/news/archive/artsNews?view=page&pageSize=10&page=").first(400).each do |report|
            naive_bayes.train("Art",report.info_to_wikify)
         end
         puts "Training Politics..."
         Report.where(:scraped_from => "http://www.reuters.com/news/archive/politicsNews?view=page&pageSize=10&page=").first(400).each do |report|
            naive_bayes.train("Politics",report.info_to_wikify)
         end
         puts "Training Sport..."
         Report.where(:scraped_from => "http://www.reuters.com/news/archive/sportsNews?view=page&pageSize=10&page=").first(400).each do |report|
            naive_bayes.train("Sport",report.info_to_wikify)
         end
         puts "Training Science..."
         Report.where(:scraped_from => "http://www.reuters.com/news/archive/scienceNews?view=page&pageSize=10&page=").first(400).each do |report|
            naive_bayes.train("Science",report.info_to_wikify)
         end
         puts "Training Technology..."
         Report.where(:scraped_from => "http://www.reuters.com/news/archive/technologyNews?view=page&pageSize=10&page=").first(400).each do |report|
            naive_bayes.train("Technology",report.info_to_wikify)
         end
         puts "Training Economy..."
         Report.where(:scraped_from => "http://www.reuters.com/news/archive/GCA-Economy2010?view=page&pageSize=10&page=").first(400).each do |report|
            naive_bayes.train("Economy",report.info_to_wikify)
         end
         puts "Training Business..."
         Report.where(:scraped_from => "http://www.reuters.com/news/archive/businessNews?view=page&pageSize=10&page=").first(400).each do |report|
            naive_bayes.train("Business",report.info_to_wikify)
         end
         puts "Training Fashion..."
         Report.where(:scraped_from => "http://www.reuters.com/news/archive/Fashion?view=page&pageSize=10&page=").first(400).each do |report|
            naive_bayes.train("Fashion",report.info_to_wikify)
         end
       
       
         puts "Classifying Health..."
         sections_array = Array.new
         Report.where(:scraped_from => "http://www.reuters.com/news/archive/healthNews?view=page&pageSize=10&page=").last(100).each do |report|
            sections_array << naive_bayes.classify(report.info_to_wikify)
         end
         semantic_naive_bayes_statistics(sections_array, "Health",date)
         
         puts "Classifying Art..."
         sections_array = Array.new
         Report.where(:scraped_from => "http://www.reuters.com/news/archive/artsNews?view=page&pageSize=10&page=").last(100).each do |report|
            sections_array << naive_bayes.classify(report.info_to_wikify)
         end
         semantic_naive_bayes_statistics(sections_array, "Art",date)
         
         puts "Classifying Politics..."
         sections_array = Array.new
         Report.where(:scraped_from => "http://www.reuters.com/news/archive/politicsNews?view=page&pageSize=10&page=").last(100).each do |report|
            sections_array << naive_bayes.classify(report.info_to_wikify)
         end
         puts "Classifying Sport..."
         sections_array = Array.new
         Report.where(:scraped_from => "http://www.reuters.com/news/archive/sportsNews?view=page&pageSize=10&page=").last(100).each do |report|
            sections_array << naive_bayes.classify(report.info_to_wikify)
         end
         semantic_naive_bayes_statistics(sections_array, "Sport",date)
         
         puts "Classifying Science..."
         sections_array = Array.new
         Report.where(:scraped_from => "http://www.reuters.com/news/archive/scienceNews?view=page&pageSize=10&page=").last(100).each do |report|
            sections_array << naive_bayes.classify(report.info_to_wikify)
         end
         semantic_naive_bayes_statistics(sections_array, "Science",date)
         
         puts "Classifying Technology..."
         sections_array = Array.new
         Report.where(:scraped_from => "http://www.reuters.com/news/archive/technologyNews?view=page&pageSize=10&page=").last(100).each do |report|
            sections_array << naive_bayes.classify(report.info_to_wikify)
         end
         semantic_naive_bayes_statistics(sections_array, "Technology",date)
         
         puts "Classifying Economy..."
         sections_array = Array.new
         Report.where(:scraped_from => "http://www.reuters.com/news/archive/GCA-Economy2010?view=page&pageSize=10&page=").last(100).each do |report|
            sections_array << naive_bayes.classify(report.info_to_wikify)
         end
         semantic_naive_bayes_statistics(sections_array, "Economy",date)
         
         puts "Classifying Business..."
         sections_array = Array.new
         Report.where(:scraped_from => "http://www.reuters.com/news/archive/businessNews?view=page&pageSize=10&page=").last(100).each do |report|
            sections_array << naive_bayes.classify(report.info_to_wikify)
         end
         semantic_naive_bayes_statistics(sections_array, "Business",date)
         
         puts "Classifying Fashion..."
         sections_array = Array.new
         Report.where(:scraped_from => "http://www.reuters.com/news/archive/Fashion?view=page&pageSize=10&page=").last(100).each do |report|
            sections_array << naive_bayes.classify(report.info_to_wikify)
         end
         semantic_naive_bayes_statistics(sections_array, "Fashion",date)
                 
      rescue Exception => e
         puts "Exception classify_it_naive_bayes"
         puts e.message
         puts e.backtrace.inspect
      end
   end
   
   def classify_it_semantic_naive_bayes(remove_outliers, threshold)
      begin
         $stdout = File.new('console.out', 'w')
         $stdout.sync = true
         
         date = Time.now
         
         $total_health_classified = 0
         $total_art_classified = 0
         $total_politics_classified = 0
         $total_sport_classified = 0
         $total_science_classified = 0    
         $total_technology_classified = 0
         $total_economy_classified = 0
         $total_business_classified = 0
         $total_fashion_classified = 0
         
         sections = ["Business", "Technology", "Science", "Health", "Sport", "Art", "Fashion", "Politics", "Economy"]
         naive_bayes = NaiveBayes.new(sections)
                  
         puts "Training Health..."
         Report.where(:scraped_from => "http://www.reuters.com/news/archive/healthNews?view=page&pageSize=10&page=").first(400).each do |report|
            naive_bayes.semantic_train("Health",report)
         end
         puts "Training Art..."
         Report.where(:scraped_from => "http://www.reuters.com/news/archive/artsNews?view=page&pageSize=10&page=").first(400).each do |report|
            naive_bayes.semantic_train("Art",report)
         end
         puts "Training Politics..."
         Report.where(:scraped_from => "http://www.reuters.com/news/archive/politicsNews?view=page&pageSize=10&page=").first(400).each do |report|
            naive_bayes.semantic_train("Politics",report)
         end
         puts "Training Sport..."
         Report.where(:scraped_from => "http://www.reuters.com/news/archive/sportsNews?view=page&pageSize=10&page=").first(400).each do |report|
            naive_bayes.semantic_train("Sport",report)
         end
         puts "Training Science..."
         Report.where(:scraped_from => "http://www.reuters.com/news/archive/scienceNews?view=page&pageSize=10&page=").first(400).each do |report|
            naive_bayes.semantic_train("Science",report)
         end
         puts "Training Technology..."
         Report.where(:scraped_from => "http://www.reuters.com/news/archive/technologyNews?view=page&pageSize=10&page=").first(400).each do |report|
            naive_bayes.semantic_train("Technology",report)
         end
         puts "Training Economy..."
         Report.where(:scraped_from => "http://www.reuters.com/news/archive/GCA-Economy2010?view=page&pageSize=10&page=").first(400).each do |report|
            naive_bayes.semantic_train("Economy",report)
         end
         puts "Training Business..."
         Report.where(:scraped_from => "http://www.reuters.com/news/archive/businessNews?view=page&pageSize=10&page=").first(400).each do |report|
            naive_bayes.semantic_train("Business",report)
         end
         puts "Training Fashion..."
         Report.where(:scraped_from => "http://www.reuters.com/news/archive/Fashion?view=page&pageSize=10&page=").first(400).each do |report|
            naive_bayes.semantic_train("Fashion",report)
         end
                                            
         puts "Classifying Health..."
         sections_array = Array.new
         Report.where(:scraped_from => "http://www.reuters.com/news/archive/healthNews?view=page&pageSize=10&page=").last(100).each do |report|
            sections_array << naive_bayes.semantic_classify(report, remove_outliers, threshold)          
         end  
         semantic_naive_bayes_statistics(sections_array, "Health",date)  
        
         puts "Classifying Art..."
         sections_array = Array.new 
         Report.where(:scraped_from => "http://www.reuters.com/news/archive/artsNews?view=page&pageSize=10&page=").last(100).each do |report|
            sections_array << naive_bayes.semantic_classify(report, remove_outliers, threshold)           
         end
         semantic_naive_bayes_statistics(sections_array, "Art",date)          
         
         puts "Classifying Politics..."
         sections_array = Array.new 
         Report.where(:scraped_from => "http://www.reuters.com/news/archive/politicsNews?view=page&pageSize=10&page=").last(100).each do |report|
            sections_array << naive_bayes.semantic_classify(report, remove_outliers, threshold)
         end
         semantic_naive_bayes_statistics(sections_array, "Politics",date)            
         
         puts "Classifying Sport..."
         sections_array = Array.new 
         Report.where(:scraped_from => "http://www.reuters.com/news/archive/sportsNews?view=page&pageSize=10&page=").last(100).each do |report|
            sections_array << naive_bayes.semantic_classify(report, remove_outliers, threshold) 
         end
         semantic_naive_bayes_statistics(sections_array, "Sport",date)        
          
         puts "Classifying Science..."
         sections_array = Array.new 
         Report.where(:scraped_from => "http://www.reuters.com/news/archive/scienceNews?view=page&pageSize=10&page=").last(100).each do |report|
            sections_array << naive_bayes.semantic_classify(report, remove_outliers, threshold)                      
         end
         semantic_naive_bayes_statistics(sections_array, "Science",date) 
         
         puts "Classifying Technology..."
         sections_array = Array.new 
         Report.where(:scraped_from => "http://www.reuters.com/news/archive/technologyNews?view=page&pageSize=10&page=").last(100).each do |report|
            sections_array << naive_bayes.semantic_classify(report, remove_outliers, threshold)                        
         end
         semantic_naive_bayes_statistics(sections_array, "Technology",date)
         
         puts "Classifying Economy..."
         sections_array = Array.new 
         Report.where(:scraped_from => "http://www.reuters.com/news/archive/GCA-Economy2010?view=page&pageSize=10&page=").last(100).each do |report|
            sections_array << naive_bayes.semantic_classify(report, remove_outliers, threshold)                        
         end
         semantic_naive_bayes_statistics(sections_array, "Economy",date)
         
         puts "Classifying Business..."
         sections_array = Array.new 
         Report.where(:scraped_from => "http://www.reuters.com/news/archive/businessNews?view=page&pageSize=10&page=").last(100).each do |report|
            sections_array << naive_bayes.semantic_classify(report, remove_outliers, threshold)                    
         end
         semantic_naive_bayes_statistics(sections_array, "Business",date)    
         
         puts "Classifying Fashion..."
         sections_array = Array.new 
         Report.where(:scraped_from => "http://www.reuters.com/news/archive/Fashion?view=page&pageSize=10&page=").last(100).each do |report|
            sections_array << naive_bayes.semantic_classify(report, remove_outliers, threshold)           
         end
         semantic_naive_bayes_statistics(sections_array, "Fashion",date)            
         
      rescue Exception => e
         puts "Exception classify_it_naive_bayes"
         puts e.message
         puts e.backtrace.inspect
      end
   end
   
   
   def semantic_naive_bayes_statistics(array_sections, expected_section,date)
      begin
         health_classified = 0
         art_classified = 0
         politics_classified = 0
         sport_classified = 0
         science_classified = 0    
         technology_classified = 0
         economy_classified = 0
         business_classified = 0
         fashion_classified = 0
         not_classified = 0
         array_sections.each do |section|
            case section
               when "Health"
                  health_classified += 1
               when "Art"
                  art_classified += 1
               when "Politics"
                  politics_classified += 1
               when "Sport"
                  sport_classified += 1
               when "Science"
                  science_classified += 1
               when "Technology"
                  technology_classified += 1
               when "Economy"
                  economy_classified += 1
               when "Business"
                  business_classified += 1
               when "Fashion"
                  fashion_classified += 1
               when "unknown"
                  not_classified += 1                  
            end
         end
         case expected_section
            when "Health"
               well_classified = health_classified
            when "Art"
               well_classified = art_classified
            when "Politics"
               well_classified = politics_classified
            when "Sport"
               well_classified = sport_classified
            when "Science"
               well_classified = science_classified
            when "Technology"
               well_classified = technology_classified
            when "Economy"
               well_classified = economy_classified
            when "Business"
               well_classified = business_classified
            when "Fashion"
               well_classified = fashion_classified
         end
         total = array_sections.size 
         not_classified = not_classified
         classified = total - not_classified    
         well_classified = well_classified  
         bad_classified = classified - well_classified
         well_classified_percentage = well_classified.to_f / (well_classified.to_f + bad_classified.to_f)
         false_positives = 2
         precision = well_classified.to_f / (well_classified.to_f + false_positives)
         recall = well_classified.to_f / (well_classified.to_f + bad_classified.to_f)
         f1_score = (2 * precision.to_f * recall.to_f) / (precision.to_f + recall.to_f)    
                 
         method = "pruebaaaa"
         
         filename = "semantic_naive_bayes_" + date.to_s  + "_statistics_" + method + ".txt"                
         File.open(filename, 'a') do |f2|   
            f2.puts
            f2.puts "Section: "  + expected_section.to_s
            f2.puts "---------------------------------------------"
            f2.puts "Health classified: " + health_classified.to_s 
            f2.puts "Art classified: " + art_classified.to_s 
            f2.puts "Politics classified: " + politics_classified.to_s 
            f2.puts "Sport classified: " + sport_classified.to_s 
            f2.puts "Science classified: " + science_classified.to_s 
            f2.puts "Technology classified: " + technology_classified.to_s 
            f2.puts "Economy classified: " + economy_classified.to_s 
            f2.puts "Business classified: " + business_classified.to_s     
            f2.puts "Fashion classified: " + fashion_classified.to_s                                       
            f2.puts
            f2.puts "Total: " + total.to_s
            f2.puts "Classified: " + classified.to_s
            f2.puts "Not classified: " + not_classified.to_s               
            f2.puts "Well classified: " + well_classified.to_s        
            f2.puts "Bad classified: " + bad_classified.to_s
            f2.puts "Well classified Percentage: " + well_classified_percentage.to_s
            f2.puts         
         end    
      rescue Exception => e
         puts "Exception semantic_naive_bayes_statistics"
         puts e.message
         puts e.backtrace.inspect
      end
   end
   
end